개념 요약을 쪽지시험 방식으로 진행했습니다.   
## <쪽지시험 문제>

1. 텐서란?
2. 텐서를 생성하는 방법은(코드)?
3. unpaired t-test(비쌍체 t-검정), p-value를 설명하시오.
4. 손실함수가 머신러닝에서 중요한 이유는?
5. 경사하강법이란 무엇이고 경사하강법은 어디에, 왜 쓰이는지?
6. 최솟값(Global Minimum)을 찾지 못하고 극솟값(Local Minimum)에서 가중치가 결정되는 경우의 예시를 두가지를 말하시오.
7. 훈련용 데이터, 검증용 데이터, 테스트용 데이터의 차이와 이들 사이의 비율(%)을 말하시오.
8. 활성화 함수란?
9. 시그모이드 함수의 모양과 수식, 시그모이드 함수의 장점과 단점, 어디에서 사용되는지(출력층 or 은닉층) 설명하시오. 
10. 역전파란 무엇이고 역전파가 왜 머신러닝에서 중요한지 설명하시오.
11. ReLU 함수의 모양과 수식, 어디에서 사용되는지(출력층 or 은닉층) 설명하시오.
12. 퍼셉트론이란?
13. 단층 퍼셉트론의 한계란?

## <쪽지시험 답변>
1. **텐서란?**    
배열(Array)나 행렬(Matrix)과 유사한 자료구조다. 파이토치에서는 텐서를 사용하여 모델의 입출력뿐만 아니라 모델의 매개변수를 부호화(Encode)하고 GPU를 활용해 연산을 가속화할 수 있다.     
e.g. N차원 텐서(https://076923.github.io/posts/Python-pytorch-2/)

2. **텐서를 생성하는 방법은(코드로 작성)?**    
torch.tensor() 또는 torch.Tensor()로 생성     
e.g. print(torch.Tensor([[1,2,3], [4,5,6]]))

3. **unpaired t-test, p-value를 설명하시오**    
unpaired t-test(비쌍체 t-검정)은 독립적인 그룹간의 평균을 비교하는데 적합 (e.g. 성별이 키와 어떤 관계가 있는지)    
*  Y(**종속변수, 독립적인 변수로 인해 얻어지는 값, 키**)가 X(**독립변수, 독립적인 변수, 성별**)에 유의미한 요소인지 확인하는 방법 → p-value 확인, p-value가 0.05보다 작으면 유의미한 요소임, 0.001보다 작으면 매우 유의미한 요소임(= 성별이 키에 미치는 영향이 확실함).

4. **손실함수가 머신러닝에서 중요한 이유는?**     
손실함수는 모델이 실제로 얼마나 정확하냐(오차)를 따질 수 있게 함. 머신러닝 모델이 훌륭하다(=정확한 모델이다)고 말하는 것은 오차 값이 매우 작다는 것을 말함.      
*   머신러닝 모델 학습은 모델의 weight(가중치)와 bias(편중)을 찾는 것을 목적으로 함. 이 값들의 추정이 올바르지 않다면 손실함수가 커지게 됨. 
<img width="798" alt="스크린샷 2024-01-11 오후 1 32 05" src="https://github.com/hanmyu/computervision_transformer_pytorch/assets/157959298/d841a8b5-5cf8-4426-84a8-d2fc7fb4e822">

*Loss 값들을 모아서 MSE로 손실함수를 만든다.    
*MSE는 머신러닝에서 많이 사용되는 손실함수입니다.

5. **경사하강법(Gradient Descent)이란 무엇이고 경사하강법은 어디에, 왜 쓰이는지?**     
함수의 기울기가 낮은 곳으로 계속 이동시켜 극값에 도달할 때까지 반복하는 알고리즘, step size/learning rate(보폭)을 조정하여 Loss 값이 최소 값이 되는 지점을 찾아감.
*   보폭이 너무 크면 정확한 모델 만들기 어려움, 보폭이 너무 작으면 너무 많은 학습을 시켜야함(epoch 수 증가). 경사하강법은 Loss Function에서 최소의 Loss 값 찾는데 쓰임.    
(참고: https://developers.google.com/machine-learning/crash-course/reducing-loss/learning-rate?hl=ko)

6. **최솟값(Global Minimum)을 찾지 못하고 극솟값(Local Minimum)에서 가중치가 결정되는 경우의 예시를 두가지를 말하시오.**    
step size(보폭)이 너무 작거나, **안장(Saddle Point)가 존재하는 Loss 함수**일 경우

7. **훈련용 데이터, 검증용 데이터, 테스트용 데이터의 차이와 이들 사이의 비율(%)을 말하시오.**    
- 훈련용 데이터: 모델 학습하는데 쓰이는 데이터 (80%)    
- 검증용 데이터: 학습이 완료된 모델을 검증하기 위해 사용하는 데이터 (10%)    
- 테스트용 데이터: 검증용 데이터를 통해 결정된 가장 성능이 우수한 모델을 최종 테스트하기위한 목적으로 사용되는 데이터 (10%)    
e.g. 문제집(훈련용 데이터), 문제집 답안지(검증용 데이터), 수능 당일 시험지(테스트용 데이터)

8. **활성화 함수란?**    
은닉층을 활성화시키기 위한 데이터    
*활성화시키다 = 인공신경망의 뉴런의 출력값을 선형에서 비선형으로 변환하는 것.    
**활성화함수는 역전파 과정에서 미분값을 통해 학습이 진행될 수 있게 한다.**

9. **시그모이드 함수의 모양과 수식, 시그모이드 함수의 장점과 단점, 어디에서 사용되는지(출력층 or 은닉층) 설명하시오.**     
시그모이드 함수 모양, 수식 ([https://ko.wikipedia.org/wiki/시그모이드_함수](https://ko.wikipedia.org/wiki/%EC%8B%9C%EA%B7%B8%EB%AA%A8%EC%9D%B4%EB%93%9C_%ED%95%A8%EC%88%98))   
장점: 기울기 폭주 문제(Exploding Gradient)가 발생하지 않음    
단점: 기울기 소실 문제(Vanishing Gradient)를 일으킴, **계층이 많아지면 많아질수록 점점 값이 0에 수렴되는 문제 발생하여 성능이 떨어짐.**      
***기울기 소실 문제: https://www.youtube.com/watch?v=BwkquF9QQLU**     
출력층에 주로 쓰임. 은닉층에서 많이 안쓰임

10. **역전파란 무엇이고 역전파가 왜 머신러닝에서 중요한지 설명하시오.**      
순전파를 통해 Loss 기록, 역전파를 통해 Loss 최소값의 w, b 찾음.
*역전파 알고리즘: 출력→ 입력 방향으로 거꾸로 전파해가며 네트워크 가중치를 수정하여 오류를 줄여나가는 방식    

11. **ReLU 함수의 모양과 수식, 어디에서 사용되는지(출력층 or 은닉층) 설명하시오.**     
Relu 함수 모양, 수식(https://ko.wikipedia.org/wiki/ReLU), 은닉층에서 사용     

12. **퍼셉트론이란?**      
인공신경망의 한 종류로써, 임곗값(threshold)을 넘기면 전달하고 임곗값보다 작으면 전달하지 않음.

13. **단층 퍼셉트론의 한계란?**      
XOR 문제를 풀 수가 없다. 복잡한 구조를 풀 수 없다.    
단층 퍼셉트론: 계층이 하나    
다층 퍼셉트론: 단층 퍼셉트론이 여러개, 은닉층이 여러개
